# BOW 기반의 문서 분류

## 1. 20 뉴스그룹 데이터 준비 및 특성 추출

20 뉴스그룹 데이터셋(20 newsgroups dataset)은 텍스트 마이닝에서 문서 분류의 성능을 측정하기 위해 가장 많이 사용되는 데이터셋 중 하나로 새로운 텍스트 마이닝 기법의 성능을 검증하기 위한 기준으로 많이 사용

**유즈넷**   
일종의 게시판과 같은 역할로 특정 주제에 맞는 뉴스를 읽거나 올릴 수 있는 곳으로 뉴스보다는 사용자들의 포스트로 여기면 됨
    

20 뉴스그룹 데이터 특징  
  + categories 매개변수를 이용하여 20개의 topic 중에서 원하는 토픽을 선택
  + remove를 이용하여 필요없는 데이터를 삭제
  + 각 데이터셋 내에서 .data 는 텍스트의 내용을, .target은 숫자로 표시된 라벨(분류)를 가져오는 데 사용
  
  
subset 매개변수는 학습 데이터셋과 검증 데이터셋을 구분하기 위해 사용

 'alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space' 만 선택 


```python
from sklearn.datasets import fetch_20newsgroups

#20개의 토픽 중 4개 선택해서 리스트로 생성
categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']

#학습 데이터셋을 가져옴
newsgroups_train = fetch_20newsgroups(subset='train',
#메일 내용에서 hint가 되는 부분을 삭제 - 순수하게 내용만으로 분류
                                      remove=('headers', 'footers', 'quotes'),
                                      categories=categories)
#검증 데이터셋을 가져옴
newsgroups_test = fetch_20newsgroups(subset='test', 
                                     remove=('headers', 'footers', 'quotes'),
                                     categories=categories)

print('#Train set size:', len(newsgroups_train.data))
print('#Test set size:', len(newsgroups_test.data))
print('#Selected categories:', newsgroups_train.target_names)
print('#Train labels:', set(newsgroups_train.target))
```

    #Train set size: 2034
    #Test set size: 1353
    #Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']
    #Train labels: {0, 1, 2, 3}
    


```python
len(newsgroups_train.target)
```




    2034



학습데이터와 검증데이터는 각기.data와 .target으로 문서의 본문과 라벨(토픽)의 내용을 갖게 된다. 카테고리와 라벨을 살펴보면, 카테고리는 문자열로된 원래값이지만 라벨은 이를 숫자로 변경한 것을 알 수 있음. 순서 동일하므로 나중에 숫자로 된 라벨 예측해 그것이 의미하는 원래 카테고리 무엇인지 알 수 있음

데이터 살펴보기


```python
print('#Train set text samples:', newsgroups_train.data[0])
print('#Train set label samples:', newsgroups_train.target[0])
print('#Test set text samples:', newsgroups_test.data[0])
print('#Test set label smaples:', newsgroups_test.target[0])
```

    #Train set text samples: Hi,
    
    I've noticed that if you only save a model (with all your mapping planes
    positioned carefully) to a .3DS file that when you reload it after restarting
    3DS, they are given a default position and orientation.  But if you save
    to a .PRJ file their positions/orientation are preserved.  Does anyone
    know why this information is not stored in the .3DS file?  Nothing is
    explicitly said in the manual about saving texture rules in the .PRJ file. 
    I'd like to be able to read the texture rule information, does anyone have 
    the format for the .PRJ file?
    
    Is the .CEL file format available from somewhere?
    
    Rych
    #Train set label samples: 1
    #Test set text samples: TRry the SKywatch project in  Arizona.
    #Test set label smaples: 2
    

newsgroups_train.target_names에는 토픽(라벨)의 값이 들어 있는데, 이 순서에 따라 .target의 숫자가 정해진다. 위에서 target_names가 ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']이고 첫 학습 데이터의 라벨이 1이므로 이 문서는 'comp.graphics'가 해당 토픽임을 알 수 있다. 반면 검증 데이터 셋의 첫 데이터는 라벨이 2이므로 해당 토픽이 'sci.space'임을 알 수 있다.

### 카운트 기반 특성 추출  

대략 내용이 파악되었다면 아래와 같이 newsgroups_train과 newsgroups_test로부터 .data와 .target을 이용하여 X_train, X_test, y_train, y_test을 추출한 후에 실제로 문서분류를 수행


```python
X_train = newsgroups_train.data   #학습 데이터셋 문서
y_train = newsgroups_train.target #학습 데이터셋 라벨

X_test = newsgroups_test.data     #검증 데이터셋 문서
y_test = newsgroups_test.target   #검증 데이터셋 라벨

#카운트 벡터 먼저 사용해서 추출
from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer(max_features=2000, min_df=5, max_df=0.5).fit(X_train)
#df는 그 단어가 나타난 문서가 몇개였는지 나타내고 있음
#min_df는 갯수로 지정 / max_df는 비율로 지정 

X_train_cv = cv.transform(X_train) # train set을 변환
print('Train set dimension:', X_train_cv.shape) 
X_test_cv = cv.transform(X_test) # test set을 변환
print('Test set dimension:', X_test_cv.shape)
#test는 절대 fit하면 안됨 --> 올바른 일반화 성능 확인할 수 없게 됨 
```

    Train set dimension: (2034, 2000)
    Test set dimension: (1353, 2000)
    

max_features, min_df, max_df 확인


```python
for word, count in zip(cv.get_feature_names()[:100], X_train_cv[0].toarray()[0, :100]):
    print(word, ':', count, end=', ')
```

    00 : 0, 000 : 0, 01 : 0, 04 : 0, 05 : 0, 10 : 0, 100 : 0, 1000 : 0, 11 : 0, 12 : 0, 128 : 0, 129 : 0, 13 : 0, 130 : 0, 14 : 0, 15 : 0, 16 : 0, 17 : 0, 18 : 0, 19 : 0, 1987 : 0, 1988 : 0, 1989 : 0, 1990 : 0, 1991 : 0, 1992 : 0, 1993 : 0, 20 : 0, 200 : 0, 202 : 0, 21 : 0, 22 : 0, 23 : 0, 24 : 0, 25 : 0, 256 : 0, 26 : 0, 27 : 0, 28 : 0, 29 : 0, 2d : 0, 30 : 0, 300 : 0, 31 : 0, 32 : 0, 33 : 0, 34 : 0, 35 : 0, 39 : 0, 3d : 0, 40 : 0, 400 : 0, 42 : 0, 45 : 0, 50 : 0, 500 : 0, 60 : 0, 600 : 0, 65 : 0, 70 : 0, 75 : 0, 80 : 0, 800 : 0, 90 : 0, 900 : 0, 91 : 0, 92 : 0, 93 : 0, 95 : 0, _the : 0, ability : 0, able : 1, abortion : 0, about : 1, above : 0, absolute : 0, absolutely : 0, ac : 0, accept : 0, acceptable : 0, accepted : 0, access : 0, according : 0, account : 0, accurate : 0, across : 0, act : 0, action : 0, actions : 0, active : 0, activities : 0, activity : 0, acts : 0, actual : 0, actually : 0, ad : 0, add : 0, added : 0, addition : 0, additional : 0, 

-->빈도수로 안하고 알파벳순으로 나열했기 때문에 0을 갖는 값이 많음

## 머신러닝과 문서 분류 과정에 대한 이해

머신러닝은 인공지능의 한 분야로 컴퓨터가 학습 통해 스스로 문제 해결하도록 알고리즘이나 통계적 모형에 관한 연구를 말하는 것으로 공통적인 알고리즘을 데이터에 적용하여 학습함으로 주어진 데이터에 적합한 문제해결 방안을 생성하는 것.크게 지도학습(Supervised Learning) - 답을 보여주면서 학습시키는 것 , 비지도학습(Unsupervised Learning), 강화학습(Reinforcement Learning)으로 나뉘며 지도학습을 사용
  
  
분류를 하기 위한 머신러닝 알고리즘으로는 나이브 베이즈, 로지스틱 회귀분석, 그리고 로지스틱 회귀분석의 변형이라고 할 수 있는 릿지와 라쏘 회귀분석이 있으며, 그 외에도 결정트리, 랜덤 포레스트, 그래디언트 부스팅, SVM, 인공신경만 등 수많은 알고리즘이 있다.  
  
  
학습모형에 대한 평가는 여러가지가 있지만 그 중 많이 사용되는 지표는 **정확도** 
이는 올바르게 예측한 데이터의 수 전체 데이터 수로 나누 값으로 검증 데이터에 있는 라벨과 예측한 라벨 비교함으로 정확도 구할 수 있음

### 나이브 베이즈 분류기(Naive Bayse Classifier)를 이용한 문서 분류


```python
from sklearn.naive_bayes import MultinomialNB #sklearn이 제공하는 MultinomialNB 를 사용
NB_clf = MultinomialNB() # 분류기 선언

NB_clf.fit(X_train_cv, y_train) #train set을 이용하여 분류기(classifier)를 학습

print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train))) #train set에 대한 예측정확도를 확인
print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test))) #test set에 대한 예측정확도를 확인
```

    Train set score: 0.827
    Test set score: 0.734
    

 X_train_cv는 카운트 벡터로 추출된 특성이고, y_train은 해당 문서에 대한 분류  
 score()는 정확도를 반환. 정확도를 계산하기 위해서는 예측을 위한 특성값과 라벨이 모두 필요하므로 fit()과 마찬가지로 둘 다 인수로 전달. 결과를 보면 학습 데이터에 대한 정확도가 검증 데이터에 대한 정확도보다 높은 것을 볼 수 있다.  
  
주어진 텍스트에 대해 분류를 예측하고 싶다면 predict() 메소드를 이용. 예측에는 라벨이 필요 없으므로 특성값만 인수로,결과는 라벨과 동일하게 숫자로 반환되므로 실제 카테고리를 알고 싶다면 newsgroups_train.target_names를 이용하여 아래와 같이 출력


```python
print('#First document and label in test data:', X_test[0], y_test[0])
print('#Second document and label in test data:', X_test[1], y_test[1])

pred = NB_clf.predict(X_test_cv[:2])

print('#Predicted labels:', pred)
print('#Predicted categories:', newsgroups_train.target_names[pred[0]], newsgroups_train.target_names[pred[1]])
```

    #First document and label in test data: TRry the SKywatch project in  Arizona. 2
    #Second document and label in test data: The Vatican library recently made a tour of the US.
     Can anyone help me in finding a FTP site where this collection is 
     available. 1
    #Predicted labels: [2 1]
    #Predicted categories: sci.space comp.graphics
    

결과 더 향상시키기 위해서 CountVectorizer 대신 TfidfVectorizer를 사용


```python
from sklearn.feature_extraction.text import TfidfVectorizer

#CountVectorizer와 동일한 인수를 사용
tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5).fit(X_train) 
X_train_tfidf = tfidf.transform(X_train) # train set을 변환
X_test_tfidf = tfidf.transform(X_test) # test set을 변환

NB_clf.fit(X_train_tfidf, y_train) #tfidf train set을 이용하여 분류기(classifier)를 새로 학습
print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인
print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인
```

    Train set score: 0.862
    Test set score: 0.742
    

분류에 대한 예측에는 특정 단어들이 기여하는데 카테고리 별로 영향 많이 미친 특성 확인해보기 


```python
import numpy as np

def top10_features(classifier, vectorizer, categories):
    feature_names = np.asarray(vectorizer.get_feature_names())
    for i, category in enumerate(categories):
        # 역순으로 정렬하기 위해 계수에 음수를 취해서 정렬 후 앞에서부터 10개의 값을 반환
        top10 = np.argsort(-classifier.coef_[i])[:10]
        # 카테고리와 영향이 큰 특성 10개를 출력
        print("%s: %s" % (category, ", ".join(feature_names[top10])))

top10_features(NB_clf, tfidf, newsgroups_train.target_names)
```

    alt.atheism: you, not, are, be, this, have, as, what, they, if
    comp.graphics: you, on, graphics, this, have, any, can, or, with, thanks
    sci.space: space, on, you, be, was, this, as, they, have, are
    talk.religion.misc: you, not, he, are, as, this, be, god, was, they
    

결과를 보면 atheism은 우리말로 무신론인데 상위 10개의 단어 중 이렇다할 것이 별로 없다. 반면 'comp.graphics'는 'graphics'라는 결정적인 단어가 있고, 'sci.space'에는 'space', 'talk.religion.misc'에는 'god'이라는 단어가 보인다.  

# 로지스틱 회귀분석을 이용한 문서 분류


```python
from sklearn.linear_model import LogisticRegression #sklearn이 제공하는 logistic regression을 사용

#count vector에 대해 regression을 해서 NB와 비교
LR_clf = LogisticRegression() #분류기 선언
LR_clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습
print('Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 
print('Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도
```

    Train set score: 0.931
    Test set score: 0.735
    

로지스틱 회귀분석을 사용해본 결과 과적합의 가능성이 있어 보임  


```python
LR_clf = LogisticRegression(max_iter=1000)
LR_clf.fit(X_train_cv, y_train) # train data를 이용하여 분류기를 학습
print('Train set score: {:.3f}'.format(LR_clf.score(X_train_cv, y_train))) # train data에 대한 예측정확도 
print('Test set score: {:.3f}'.format(LR_clf.score(X_test_cv, y_test))) # test data에 대한 예측정확도
```

    Train set score: 0.976
    Test set score: 0.681
    

tfidf의 과적합 예상으로 cv 역시 과적합의 가능성이 있는지 확인해본 결과 tfidf에 비해서 더 높은 과적합 가능성이 보임

과적합이 예상되기 때문에 이러한 과적합을 막기 위해서 아래와 같은 방법들 사용

## 릿지회귀

회귀분석에 정규화를 사용하는 알고리즘으로 최적화를 위한 목적함수에 정규화 항목을 넣어 특성에 대한 계수가 지나치게 커지는 것을 억제


```python
from sklearn.linear_model import RidgeClassifier

ridge_clf = RidgeClassifier() #릿지 분류기 선언
ridge_clf.fit(X_train_tfidf, y_train) #학습
print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))
print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))
```

    Train set score: 0.959
    Test set score: 0.735
    

릿지회귀를 실시해본 결과 과적합을 줄이기 위해서 사용한 것인데 오히려 train set결과가 더 오름. 이런 경우 alpha를 사용해서 정규화 정도를 조절.


```python
ridge_clf = RidgeClassifier(alpha=5) #릿지 분류기 선언
ridge_clf.fit(X_train_tfidf, y_train) #학습

print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))
print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))
```

    Train set score: 0.909
    Test set score: 0.741
    

(원래는 alpha값 바꿀때 test set를 사용하면 안됨. train set를 다시 train과 test로 나눠서 결과 확인해봐야함) 

top10_features()를 이용해 주요단어 분석  
위에서 설정해둔 영향을 많이 미치는 단어 10개 가져와서 실시하도록


```python
top10_features(ridge_clf, tfidf, newsgroups_train.target_names)
```

    alt.atheism: atheism, religion, bobby, islam, atheists, islamic, deletion, atheist, motto, punishment
    comp.graphics: graphics, image, file, 3d, computer, hi, files, looking, points, code
    sci.space: space, orbit, nasa, moon, launch, spacecraft, shuttle, earth, lunar, flight
    talk.religion.misc: christian, jesus, christians, fbi, order, objective, christ, his, koresh, children
    

위에서 나이브베이즈가 you, are, not, be, this와 같은 단어들을 보여준 것에 비해 릿지회귀는 더 그럴듯한 결과 보여주고 있고 이것이 로지스틱 회귀분석 계열의 장점. 분석 결과를 설명하고 해석에 매우 용이하고 다른 방법으론 라쏘 회귀분석이 있음 


## 라쏘회귀

0에 가까워지면 아예 사용하지 않는 것이 라쏘회귀    
    
  현재 사이킷런은 라쏘 따로 제공하지 않고 기존의 로지스틱 분석에 정규화 방식 L1를 선택하도록 지원.동시에 알고리즘 'liblinear' 선택. 릿지 회귀의 alpha와 같은 기능을 하는 매개변수로 C를 제공하는데, 주의할 점은 C는 alpha의 역수로 alpha를 올리면 정규화가 강해지지만 C는 값이 커지면 정규화가 약해짐


```python
lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1) 
# Lasso는 동일한 LogisticRegression을 사용하면서 매개변수로 지정
lasso_clf.fit(X_train_tfidf, y_train) # train data로 학습

print('#Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))
print('#Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))

# 계수(coefficient) 중에서 0이 아닌 것들의 개수를 출력 -- 특성을 줄여줌
print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1]) 
```

    #Train set score: 0.821
    #Test set score: 0.725
    #Used features count: 432 out of 2000
    

Train set score: 0.931이 나왔던 것에 비해 과적합은 많이 눌러준 것을 확인할 수 있음  
    
결과를 보면 정확도는 떨어졌고, 사용된 특성은 전체 2,000개 중에서 437개로 줄어든 것을 볼 수 있다. 라쏘와 같은 방식으로 특성의 수를 줄이는 것을 특성 선택(feature selection)이라고 한다. 특성을 줄이면서 얻어지는 장점은 우리가 연관성이 떨어지는 특성들을 배제하고 중요한 특성에 집중할 수 있다는 것

라쏘에서도 top10_features()를 이용해 주요단어 분석


```python
top10_features(lasso_clf, tfidf, newsgroups_train.target_names)
```

    alt.atheism: bobby, atheism, atheists, islam, religion, islamic, motto, atheist, satan, vice
    comp.graphics: graphics, image, 3d, file, computer, hi, video, files, looking, sphere
    sci.space: space, orbit, launch, nasa, spacecraft, flight, moon, dc, shuttle, solar
    talk.religion.misc: fbi, christian, christians, christ, order, jesus, children, objective, context, blood
    

# 결정트리 등을 이용한 기타 문서 분류 방법

머신러닝 알고리즘 중 하나이므로 문서 분류에 사용. 결정트리의 장점 중 하나는 왜 그와 같이 예측했는지에 대해 체계적인 설명이 가능하다는 것이다. 모형이 학습되면 결정트리를 그려서 분류가 되는 과정을 살펴볼 수 있다. 다만 문제는 특성이 너무 많은 경우, 보기가 쉽지 않아  특성의 수를 비롯한 여러가지를 고려해서 사용

사이킷런은 결정트리를 위한 DecisionTreeClassifier 클래스(1), 결정트리 기반의 앙상블 모형 중 하나인 랜덤포레스트를 위한 RandomForestClassifier 클래스(2), 결정트리 기반의 모형 중에서 막강한 성능을 자랑하는 그래디언트 부스팅을 지원하는 GradientBoostingClassifier 클래스(3)를 제공하므로 어렵지 않게 구현이 가능


```python
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier

tree = DecisionTreeClassifier(random_state=7)
tree.fit(X_train_tfidf, y_train)
print('#Decision Tree train set score: {:.3f}'.format(tree.score(X_train_tfidf, y_train)))
print('#Decision Tree test set score: {:.3f}'.format(tree.score(X_test_tfidf, y_test)))

forest = RandomForestClassifier(random_state=7)
forest.fit(X_train_tfidf, y_train)
print('#Random Forest train set score: {:.3f}'.format(forest.score(X_train_tfidf, y_train)))
print('#Random Forest test set score: {:.3f}'.format(forest.score(X_test_tfidf, y_test)))

gb = GradientBoostingClassifier(random_state=7)
gb.fit(X_train_tfidf, y_train)
print('#Gradient Boosting train set score: {:.3f}'.format(gb.score(X_train_tfidf, y_train)))
print('#Gradient Boosting test set score: {:.3f}'.format(gb.score(X_test_tfidf, y_test)))
```

    #Decision Tree train set score: 0.977
    #Decision Tree test set score: 0.532
    #Random Forest train set score: 0.977
    #Random Forest test set score: 0.683
    #Gradient Boosting train set score: 0.936
    #Gradient Boosting test set score: 0.693
    

결과를 보면 결정트리와 랜덤 포레스트는 학습 데이터에 대한 정확도가 높다. 이는 결정트리가 일반적으로 학습 데이터에 과적합되는 성향이 매우 강하기 때문이다. 둘째로는 그래디언트 부스팅으로 갈수록 성능이 높아지고 있지만 결과는 그닥 좋지 않음. 이는 최적화를 위한 하이퍼 파라미터 탐색이 이루어지지 않은 원인도 있지만, 문서 분류의 경우에는 전반적으로 결정트리 기반의 알고리즘이 좋은 성능을 보여주지는 못한다.
  
결정트리에서도 나이브베이즈, 로지스틱 회귀분석과 마찬가지로 어떤 단어가 분류에 가장 큰 영향을 미쳤는지 알 수 있을까? 결정트리는 계수라는 개념이 없기 때문에 위에서와 같은 방법으로는 파악이 어렵다. 그러나 coef_ 대신 feature_importances_를 제공하기 때문에 어떤 특성이 전체 트리에서 중요한 영향을 미쳤는지 알 수 있다. 

그래디언트 부스팅 분류기로부터 feature_importances_를 가져와 중요도가 높은 단어부터 40개만 실시


```python
sorted_feature_importances = sorted(zip(tfidf.get_feature_names(), gb.feature_importances_), key=lambda x: x[1], reverse=True)
for feature, value in sorted_feature_importances[:40]:
    print('%s: %.3f' % (feature, value), end=', ')
```

    space: 0.126, graphics: 0.080, atheism: 0.025, thanks: 0.024, file: 0.021, orbit: 0.020, god: 0.018, hi: 0.017, jesus: 0.016, nasa: 0.016, image: 0.015, files: 0.014, christ: 0.011, bobby: 0.010, launch: 0.010, moon: 0.010, christian: 0.010, looking: 0.010, fbi: 0.009, christians: 0.009, 3d: 0.008, atheists: 0.008, not: 0.008, you: 0.008, islamic: 0.008, religion: 0.008, spacecraft: 0.007, flight: 0.007, computer: 0.007, islam: 0.006, ftp: 0.006, atheist: 0.006, color: 0.005, kent: 0.005, his: 0.005, software: 0.005, card: 0.005, sea: 0.005, koresh: 0.005, people: 0.005, 

결정트리의 feature_importances_는 coef_와 결정적으로 다른 점이 하나 있는데 결정트리에서는 서로 비슷한 성격을 갖는 두 단어 중 하나의 단어가 분류에 먼저 사용되면 다른 단어는 상대적으로 중요도가 떨어지는 것으로 이는 즉 두 단어가 비슷한 계수값을 가져도 결정트리에서는 완전히 다른 값을 가질 수 있다는 것이다. 결정트리의 좋은 점은 왜 그런 결과가 나왔는지 보다 명확하게 제시할 수 있지만, 특성의 수가 상대적으로 매우 많은 텍스트 분류에서는 완전한 결정트리는 너무 크고 어려워 특성의 수를 적은 수로 제한하는 것이 좋다. 하지만 이는 정확도가 떨어진다는 단점도 있다.

# 성능을 높이는 방법들

1. 토큰화, 정규화 등을 좀 더 세심하게 해보기 


```python
# 필요한 library들을 import
from nltk.corpus import stopwords
cachedStopWords = stopwords.words("english")

from nltk.tokenize import RegexpTokenizer
from nltk.stem.porter import PorterStemmer
import re

RegTok = RegexpTokenizer("[\w']{3,}") # 정규포현식으로 토크나이저를 정의
english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴

def tokenizer(text):
    tokens = RegTok.tokenize(text.lower()) #이렇게 해도 되는지 확인
    # stopwords 제외
    words = [word for word in tokens if (word not in english_stops) and len(word) > 2]
    # portr stemmer 적용
    features = (list(map(lambda token: PorterStemmer().stem(token),words)))
    return features

tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=0.5) # 새로 정의한 토크나이저 사용
X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환
X_test_tfidf = tfidf.transform(X_test) # test set을 변환

#tfidf vector를 이용해서 분류기 학습
LR_clf = LogisticRegression() #분류기 선언
LR_clf.fit(X_train_tfidf, y_train) # train data를 이용하여 분류기를 학습
print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) # train data에 대한 예측정확도 
print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) # test data에 대한 예측정확도
```

    #Train set score: 0.930
    #Test set score: 0.750
    


```python
len(LR_clf.coef_[0])
```




    2000



특성 수를 늘린다면?


```python
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(tokenizer=tokenizer).fit(X_train) 

X_train_tfidf = tfidf.transform(X_train) # train set을 변환
print('#Train set dimension:', X_train_tfidf.shape) # 실제로 몇개의 특성이 사용되었는지 확인
X_test_tfidf = tfidf.transform(X_test) # test set을 변환
print('#Test set dimension:', X_test_tfidf.shape)

ridge_clf = RidgeClassifier(alpha=2.4)
ridge_clf.fit(X_train_tfidf, y_train) #학습
print('#Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))
print('#Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))

NB_clf = MultinomialNB(alpha=0.01) # 분류기 선언
NB_clf.fit(X_train_tfidf, y_train) #train set을 이용하여 분류기(classifier)를 학습
print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train))) #train set에 대한 예측정확도를 확인
print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test))) #test set에 대한 예측정확도를 확인
```

    C:\Users\juhee\anaconda3\lib\site-packages\sklearn\feature_extraction\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'
      warnings.warn("The parameter 'token_pattern' will not be used"
    

    #Train set dimension: (2034, 20085)
    #Test set dimension: (1353, 20085)
    #Train set score: 0.968
    #Test set score: 0.768
    #Train set score: 0.971
    #Test set score: 0.793
    

# 한글 문서의 분류


```python
import pandas as pd
df = pd.read_csv('daum_movie_review.csv')
df.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
      <th>rating</th>
      <th>date</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>
      <td>1</td>
      <td>2018.10.29</td>
      <td>인피니티 워</td>
    </tr>
    <tr>
      <th>1</th>
      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>
      <td>10</td>
      <td>2018.10.26</td>
      <td>인피니티 워</td>
    </tr>
    <tr>
      <th>2</th>
      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>
      <td>8</td>
      <td>2018.10.24</td>
      <td>인피니티 워</td>
    </tr>
    <tr>
      <th>3</th>
      <td>이 정도면 볼만하다고 할 수 있음!</td>
      <td>8</td>
      <td>2018.10.22</td>
      <td>인피니티 워</td>
    </tr>
    <tr>
      <th>4</th>
      <td>재미있다</td>
      <td>10</td>
      <td>2018.10.20</td>
      <td>인피니티 워</td>
    </tr>
  </tbody>
</table>
</div>



어떤 영화가 있고 각 영화에 대해 리뷰의 수가 몇개가 되는지 확인


```python
df.title.value_counts()
```




    신과함께      4947
    택시운전사     2322
    인피니티 워    2042
    범죄도시      1939
    곤지암       1547
    라라랜드      1150
    코코         778
    Name: title, dtype: int64



리뷰의 수가 영화별로 차이나는 것을 확인할 수 있고 이러한 데이터 셋을 **불균형 데이터 셋(imbalanced data set)**이라고 한다.   

문제 해결 방법으로는 
1. 언더샘플링을 통해 갯수가 많은 분류들의 데이터 수를 적은 분류의 수에 맞추기
2. 오버샘플링을 이용해 데이터 수가 적은 분류의 수를 늘리기

train_test_split을 이용해 train set과 test set 분리하기


```python
from sklearn.model_selection import train_test_split

# split data and labels into a training and a test set
X_train, X_test, y_train, y_test = train_test_split(df.review, df.title, random_state=0)
# 비율을 지정하지 않으면 75:25로 분할됨
print('#Train set size:', len(X_train)) # 실제로 몇개의 특성이 사용되었는지 확인
print('#Test set size:', len(X_test))
```

    #Train set size: 11043
    #Test set size: 3682
    


```python
from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import
#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import
okt = Okt()

print(okt.morphs(X_train[1])) #둘째 리뷰에 대해 형태소 단위로 tokenize
print(okt.nouns(X_train[1])) #둘째 리뷰에서 명사만 추출
print(okt.pos(X_train[1]))
```

    ['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']
    ['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']
    [('몰입', 'Noun'), ('할수밖에', 'Verb'), ('없다', 'Adjective'), ('.', 'Punctuation'), ('어렵게', 'Adjective'), ('생각', 'Noun'), ('할', 'Verb'), ('필요없다', 'Adjective'), ('.', 'Punctuation'), ('내', 'Noun'), ('가', 'Josa'), ('전투', 'Noun'), ('에', 'Josa'), ('참여', 'Noun'), ('한', 'Determiner'), ('듯', 'Noun'), ('손', 'Noun'), ('에', 'Josa'), ('땀', 'Noun'), ('이남', 'Noun'), ('.', 'Punctuation')]
    

일반적으로 문서를 대상으로 분석하는 경우에는 명사 만으로도 좋은 결과를 보이는 경우가 많기 때문에 우선 okt.nouns()를 TfidfVectorizer의 토크나이저로 지정해서 로지스틱 회귀분석 실시


```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

#Twitter 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용
tfidf = TfidfVectorizer(tokenizer=okt.nouns, max_features=2000, min_df=5, max_df=0.5) 

X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector
X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector

# logistic regression 분류기 선언
clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100
clf.fit(X_train_tfidf, y_train) # 분류기 학습
print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도
print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도
```

    #Train set score: 0.756
    #Test set score: 0.695
    

테스트 데이터에 대해 모형이 어떻게 예측하는지 보기 위해, 테스트 데이터 앞 10개의 리뷰에 대해 실제 영화제목, 예측한 제목, 리뷰의 순으로 아래와 같이 출력했다.


```python
print('실제영화제목, 예측한 제목, 리뷰')
for content in zip(y_test[:10], clf.predict(X_test_tfidf[:10]), X_test[:10]):
    print(content)
```

    실제영화제목, 예측한 제목, 리뷰
    ('범죄도시', '신과함께', '오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.')
    ('범죄도시', '범죄도시', '조연들이 눈에 박힌다. 간만에 집중 ㅎ')
    ('코코', '코코', '대감동을 선사. 인사이드 아웃을 잇는 픽사의 감동스토리. 신과함께의 멕시코판이라고나할까요??')
    ('신과함께', '신과함께', '돈이 안아까웠던 영화ᆞᆞ  정말 좋았다')
    ('신과함께', '신과함께', '역시 김용화감독이 영화는 잘 만들어요. 이제 VFX 제작 부문도 헐리우드 수준 이상입니다.')
    ('택시운전사', '택시운전사', '민주화를 위해 힘써주신 분들께 감사하는 마음으로 살아야겠다.')
    ('신과함께', '신과함께', '잠만 자다 왔음')
    ('신과함께', '신과함께', '오랜만에 잼있고 좋은 영화를 봤다')
    ('범죄도시', '신과함께', '잼남')
    ('범죄도시', '인피니티 워', '대박~~')
    

## 성능 개선하기 위한 노력

모든 품사 다 사용한 경우 


```python
tfidf = TfidfVectorizer(tokenizer=okt.morphs, max_features=2000, min_df=5, max_df=0.5) # 명사 대신 모든 형태소를 사용
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100
clf.fit(X_train_tfidf, y_train)
print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도
print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도
```

    #Train set score: 0.777
    #Test set score: 0.696
    

전체를 다 사용하는 대신에 명상, 동사, 형용사만 선별하고 twit_tokenizer 함수를 정의하고 함수를 이용해 특성추출을 한 후에 분류


```python
def twit_tokenizer(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용
    target_tags = ['Noun', 'Verb', 'Adjective']
    result = []
    for word, tag in okt.pos(text, norm=True, stem=True):
        if tag in target_tags:
            result.append(word)
    return result

tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=0.5) #명사, 동사, 형용사를 이용하여 tfidf 생성
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

clf = LogisticRegression(max_iter=1000) # 충분한 학습을 위해 max_iter를 1,000으로 설정, 기본은 100
clf.fit(X_train_tfidf, y_train)
print('#Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train))) # train data 예측정확도
print('#Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test))) # test data 예측정확도
```

    #Train set score: 0.784
    #Test set score: 0.713
    

결과가 높아진 것을 확인할 수 있고 품사를 선별하는 것이 도움이 된다는 것을 알 수 있다. 모든 품사를 사용하는 것은 같은 단어에 대해 서로 다른 품사인 경우 구분을 하지 못하기 때문이다. 구분할 수 있게 만드는 방법으로는 품사명을 붙여서 하나의 단어로 만드는 것이다. 

새로 토크나이저를 정의하고 학습 데이터 중 둘째 리뷰에 대해 적용해보기


```python
# 모든 형태소를 다 사용하고 품사를 알 수 있도록 하면?
def twit_tokenizer2(text):
    result = []
    for word, tag in okt.pos(text, norm=True, stem=True):
        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함
    return result

print(twit_tokenizer2(X_train[1]))
```

    ['몰입/Noun', '하다/Verb', '없다/Adjective', './Punctuation', '어렵다/Adjective', '생각/Noun', '하다/Verb', '필요없다/Adjective', './Punctuation', '내/Noun', '가/Josa', '전투/Noun', '에/Josa', '참여/Noun', '한/Determiner', '듯/Noun', '손/Noun', '에/Josa', '땀/Noun', '이남/Noun', './Punctuation']
    

alpha값을 이용해 릿지 회귀분서과 라쏘 회귀분석 둘 다 실시


```python
from sklearn.linear_model import RidgeClassifier

ridge_clf = RidgeClassifier(alpha=1.6)
ridge_clf.fit(X_train_tfidf, y_train)
print('#Ridge Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))
print('#Ridge Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))

from sklearn.linear_model import LogisticRegression
import numpy as np
lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)
lasso_clf.fit(X_train_tfidf, y_train)
print('#Lasso Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))
print('#Lasso Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))
print('#Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])
```

    #Ridge Train set score: 0.797
    #Ridge Test set score: 0.714
    #Lasso Train set score: 0.700
    #Lasso Test set score: 0.694
    #Used features count: 950 out of 2000
    

릿지 회귀분석은 정확도 0.726으로 확실히 더 나은 결과를 보여주고 있다. 반면 라쏘 회귀분석은 0.696으로 더 떨어진 성능을 보여주고 있다.   
  
나이브 베이즈로 실행해보기


```python
from sklearn.naive_bayes import MultinomialNB

NB_clf = MultinomialNB(alpha=0.1)
NB_clf.fit(X_train_tfidf, y_train)
print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))
print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))
```

    Train set score: 0.773
    Test set score: 0.710
    

로지스틱 회귀분석보다도 더 떨어진 결과를 보인다. 나이브 베이즈 분석이 항상 좋은 결과를 보이는 것은 아니라는 사실을 알 수 있다. 즉 최적의 성능을 얻기 위해서는 다양한 모형과 세팅을 모두 시도해볼 수 밖에 없다.
